host: 0.0.0.0
port: 8052
apiPathPrefix: "/api/*"
openAI:
  secretKey: "<openai secret key>"
  model: "gpt-4o-mini"
  temperature: null # What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. We generally recommend altering this or top_p but not both.
  topP: null # An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered. We generally recommend altering this or temperature but not both.
  maxTokens: null # An upper bound for the number of tokens that can be generated for a completion, including visible output tokens and reasoning tokens.
  makeSchema:
    samples: 3 # Number of snippets to sample when generating the schema
  generateXMLObjectWithoutSchema:
    maxAttempts: 3
    systemPrompt: "You are a semantic/domain object extractor. You are provided snippets of HTML and generate XML output. The XML output should contain a representation of the domain object present in the HTML input."
  generateXMLSchema:
    maxAttempts: 3
    systemPrompt: "You are an XML schema generator. You are provided %s different XML snippets and must generate an XML schema capable of validating all of them."
